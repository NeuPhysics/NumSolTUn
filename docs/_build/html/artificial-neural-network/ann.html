<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Artificial Neural Networks Basics &#8212; Computational Neutrino Physics</title>
    
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/modify.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/style.css" type="text/css" />
    <link rel="stylesheet" href="../_static/modify.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     'Pi',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tech" href="../tech/index.html" />
    <link rel="prev" title="Artificial Neural Networks" href="index.html" />
<script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-66327435-2']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script');
        ga.type = 'text/javascript';
        ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(ga, s);
    })();
</script>

<!-- Toggle Environment Begin -->
  <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .admonition-title").show();
        $(".toggle .admonition-title").click(function() {
            $(this).parent().children().not(".admonition-title").toggle(400);
            $(this).parent().children(".admonition-title").toggleClass("open");
        })
    });
    </script>
<!-- Toggle Environment End -->

   
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9">
  <link rel="canonical" href="http://computational.neutrino.xyz/artificial-neural-network/ann.html"/>



  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ TeX: { extensions: ["color.js","cancel.js", "AMSmath.js", "AMSsymbols.js"] }});
  </script>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
    MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
      cancel: ["Extension","cancel"]
      });
   });
   </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      processEscapes: true
    }
  });
</script>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        overlr: ['\\overset\\leftrightarrow{\#1}',1],
        overl: ['\\overset\leftarrow{\#1}',1],
        overr: ['\\overset\rightarrow{\#1}',1],
        bra: ['\\left\\langle \#1\\right|',1],
        ket: ['\\left| \#1\\right\\rangle',1],
        braket: ['\\langle \#1 \\mid \#2 \\rangle',2],
        avg: ['\\left< \#1 \\right>',1],
        slashed: ['\\cancel{\#1}',1],
        bold: ['\\boldsymbol{\#1}',1],
        sech: ['\\operatorname{sech}{\#1}',1],
        csch: ['\\operatorname{csch}{\#1}',1]
      }
    }
  });
  </script>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
 
  </head>
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../tech/index.html" title="Tech"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Artificial Neural Networks"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Computational Neutrino Physics</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Artificial Neural Networks</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="artificial-neural-networks-basics">
<h1>Artificial Neural Networks Basics<a class="headerlink" href="#artificial-neural-networks-basics" title="Permalink to this headline">¶</a></h1>
<p>Artificial neural networks works pretty well for equation solving.</p>
<div class="section" id="universal-approximators">
<h2>Universal Approximators<a class="headerlink" href="#universal-approximators" title="Permalink to this headline">¶</a></h2>
<p>Mawell Stinchcombe and Halber White proved that no theoretical constraints for the feedforward networks to approximate any measureable function. In principle one can use feedforward networks to approximate measurable functions to any accuracy.</p>
<p>However the convergence slows done if we have a lot of hidden units. There is a balance between accuracy and convergence rate. More hidden units means slow convergence but more accuracy.</p>
<p>Here is a quick review of the history of this topic.</p>
<div class="note admonition">
<p class="first admonition-title">Kolmogorov&#8217;s Theorem</p>
<p>Kolmogorov&#8217;s theorem shows that one can use finite number of carefully chosen continuous functions to exactly mix up by sums and multiplication with weights to a continuous multivariable fnction on a copact set.</p>
<p class="last"><a class="reference external" href="http://neuron.eng.wayne.edu/tarek/MITbook/chap2/2_3.html">Here is the exact math.</a></p>
</div>
<ol class="arabic simple">
<li>Cybenko 1989</li>
</ol>
<p>Cybenko proved that</p>
<div class="math">
\[\sum_k v_k \sigma(w_k x + u_k)\]</div>
<p>is a good approximation of continuous functions because it is dense in continous function space. In this result, <span class="math">\(\sigma\)</span> is a continuous sigmoidal function and the parameters are real.</p>
<ol class="arabic simple" start="2">
<li>Hornik 1989</li>
</ol>
<p>&#8220;Single hidden layer feedforward networks can approximate any measurable functions arbitrarily well regardless of the activation function, the dimension of the input and the input space environment.&#8221;
(<a class="reference external" href="http://deeplearning.cs.cmu.edu/notes/Sonia_Hornik.pdf">http://deeplearning.cs.cmu.edu/notes/Sonia_Hornik.pdf</a>)</p>
<div class="note admonition">
<p class="first admonition-title">Dense</p>
<p class="last">Set A is dense in set X means that we can use A to arbitarily approximate X. Mathematically for any given element in X, the neighbour of x always has nonzero intersection.</p>
</div>
<div class="note admonition">
<p class="first admonition-title">Measurable Function</p>
<p class="last">Basically it means continuous.</p>
</div>
<div class="section" id="refs">
<h3>Refs<a class="headerlink" href="#refs" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li>Kolmogorov, A. N. (1957). &#8220;On the Representation of Continuous Functions of Several Variables by Superposition of Continuous Functions of one Variable and Addition,&#8221; Doklady Akademii. Nauk USSR, 114, 679-681.</li>
<li>Maxwell Stinchcombe, Halbert White (1989). <a class="reference external" href="http://www.sciencedirect.com/science/article/pii/0893608089900208">&#8220;Multilayer feedforward networks are universal approximators&#8221;</a> . Neural Networks, Vol 2, 5, 359-366.</li>
</ol>
</div>
</div>
<div class="section" id="activation-functions">
<h2>Activation Functions<a class="headerlink" href="#activation-functions" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li>Uni-Polar Sigmoid Function</li>
</ol>
<div class="math">
\[\frac{1}{1+e^{-x}}\]</div>
<div class="figure align-center" id="id3">
<img alt="../_images/sigmoidFunction.png" src="../_images/sigmoidFunction.png" />
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text">Sigmoid function</span></p>
</div>
<ol class="arabic simple" start="2">
<li>Bipolar Sigmoid Function</li>
</ol>
<div class="math">
\[\frac{1-e^{-x}}{1+e^{-x}}\]</div>
<div class="figure align-center" id="id4">
<img alt="../_images/bipolarSigmoid.png" src="../_images/bipolarSigmoid.png" />
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text">Bipolar Sigmoid</span></p>
</div>
<ol class="arabic simple" start="3">
<li>Hyperbolic Tangent</li>
</ol>
<div class="math">
\[\tanh(x) = \frac{\sinh(x)}{\cosh(x)} = \frac{e^{x} - e^{-x}}{e^x + e^{-x}}\]</div>
<div class="figure align-center" id="id5">
<img alt="../_images/tanh.png" src="../_images/tanh.png" />
<p class="caption"><span class="caption-number">Fig. 3 </span><span class="caption-text">Hyperbolic tangent</span></p>
</div>
<ol class="arabic simple" start="4">
<li>Radial Basis Function</li>
</ol>
<div class="figure align-center" id="id6">
<img alt="../_images/unnormalized_radial_basis_functions.svg.png" src="../_images/unnormalized_radial_basis_functions.svg.png" />
<p class="caption"><span class="caption-number">Fig. 4 </span><span class="caption-text">Two unnormalized Gaussian radial basis functions in one input dimension. The basis function centers are located at x1=0.75 and x2=3.25. Source <a class="reference external" href="https://en.wikipedia.org/wiki/Radial_basis_function#/media/File:Unnormalized_radial_basis_functions.svg">Unnormalized Radial Basis Functions</a></span></p>
</div>
<ol class="arabic simple" start="5">
<li>Conic Section Function</li>
</ol>
<div class="section" id="reffs">
<h3>Reffs<a class="headerlink" href="#reffs" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><a class="reference external" href="http://www.cscjournals.org/manuscript/Journals/IJAE/volume1/Issue4/IJAE-26.pdf">Performance Analysis of Various Activation Functions in Generalized MLP Architectures of Neural Networks</a></li>
</ol>
</div>
</div>
<div class="section" id="solving-differential-equations">
<h2>Solving Differential Equations<a class="headerlink" href="#solving-differential-equations" title="Permalink to this headline">¶</a></h2>
<p>The problem here to solve is</p>
<div class="math">
\[\frac{d}{dt}y(t)= - y(t),\]</div>
<p>with initial condition <span class="math">\(y(0)=1\)</span>.</p>
<p>To construct a single layered neural network, the function is decomposed using</p>
<div class="math">
\[\begin{split}y(t_i)&amp; = y(t_0) + t_i v_k f(t_i w_k+u_k) \\
&amp;= 1+t_i v_k f(t_i w_k+u_k) ,\end{split}\]</div>
<p>where <span class="math">\(y(t_0)\)</span> is the initial condition and <span class="math">\(k\)</span> is summed over.</p>
<div class="note admonition">
<p class="first admonition-title">Articifial Neural Network</p>
<p class="last">THIS WILL BE NOTES FOR BASIC IDEAS OF ARTIFICIAL NEURAL NETWORK.</p>
</div>
<p>Presumably this should be the gate controlling trigering of the neuron or not. Therefore the following expit function serves this purpose well,</p>
<div class="math">
\[f(x) = \frac{1}{1+\exp(-x)}.\]</div>
<p>One important reason for chosing this is that a lot of expressions can be calculated analytically and easily.</p>
<div class="note admonition">
<p class="first admonition-title">Fermi-Dirac Distribution</p>
<p class="last">Aha, the Fermi-Dirac distribution.</p>
</div>
<p>With the form of the function to be solved, we can define a cost</p>
<div class="math">
\[I=\sum_i\left( \frac{dy}{dt}(t_i)+y(t_i) \right)^2,\]</div>
<p>which should be minimized to 0 if our struture of networks is optimized for this problem.</p>
<p>Now the task becomes clear:</p>
<ol class="arabic simple">
<li>Write down the cost analytically;</li>
<li>Minimized cost to find structure;</li>
<li>Substitute back to the function and we are done.</li>
</ol>
</div>
<div class="section" id="overfitting">
<h2>Overfitting<a class="headerlink" href="#overfitting" title="Permalink to this headline">¶</a></h2>
<p>It is possible that we could over fit a network so that it works only for the training data. To avoid that, people use several strategies.</p>
<ol class="arabic simple">
<li>Split data into two parts, one for training and one for testing. <a class="reference external" href="https://www.youtube.com/watch?v=S4ZUwgesjS8">A youtube video</a></li>
<li>Throw more data in. At least 10 times as many as examples as the DoFs of the model.  <a class="reference external" href="https://www.youtube.com/watch?v=S4ZUwgesjS8">A youtube video</a></li>
<li>Regularization by plugin a artifical term to the cost function, as an example we could add the . <a class="reference external" href="https://www.youtube.com/watch?v=S4ZUwgesjS8">A youtube video</a></li>
</ol>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Computational Neutrino Physics</a></h1>



<p class="blurb">Computational Neutrino Physics</p>



<p>
<iframe src="http://ghbtns.com/github-btn.html?user=NeuPhysics&repo=computational-neutrino-physics&type=watch&count=true&size=large"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>


<h3>ToC</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../preliminary/index.html">Preliminary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/index.html">Python Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../numerical-methods/index.html">Numerical Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../neutrino-oscillations/index.html">Numerical Neutrino Osillations</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Artificial Neural Networks</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Artificial Neural Networks Basics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#universal-approximators">Universal Approximators</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activation-functions">Activation Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#solving-differential-equations">Solving Differential Equations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#overfitting">Overfitting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tech/index.html">Tech</a></li>
</ul>


<ul>
	<li><a href="genindex.html">INDEX</a></li>
</ul>
<h3>Links</h3>
<ul>
   <li class="toctree-l1"><a href="http://neutrino.xyz" style="color:orange;"><i class="fa fa-globe"></i>&nbsp;Neutrino Physics</a></li>
   <li class="toctree-l1"><a href="http://physics.openmetric.org" style="color:orange;"><i class="fa fa-fire"></i>&nbsp;Physics Notes</a></li>
   <li class="toctree-l1"><a href="http://neutrino.xyz/neutrino-map" style="color:orange;"><i class="fa fa-map-signs"></i>&nbsp;Neutrino Map</a></li>
</ul>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script><h3>Bug Report and Chat</h3>
<p>

<a href="https://github.com/NeuPhysics/computational-neutrino-physics/issues"><img src="https://img.shields.io/badge/GitHub-Issues-blue.svg"></a><br><br>



<a href="https://gitter.im/NeuPhysics/neutrino?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge" target="_blank"><img src="https://badges.gitter.im/NeuPhysics/neutrino.svg"></a>

        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer" style="border-top:1px solid #B1B4B6;">

<!-- 多说评论框 start -->
<!--
  <div class="ds-thread" data-thread-key="" data-title="Artificial Neural Networks Basics &#8212; Computational Neutrino Physics" data-url=""></div>
-->
<!-- 多说评论框 end -->
<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<!--
<script type="text/javascript">
var duoshuoQuery = {short_name:"sci2fi"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  </script>
-->
<!-- 多说公共JS代码 end -->

<!-- Disqus BEGIN -->
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'neuphysics';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
<!-- Disqus END -->


      &copy;2016, Lei Ma. | <a href="index.html">Licenses</a>
      |
      <a href="/genindex.html">Index</a>
      |
      
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.5.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="../_sources/artificial-neural-network/ann.rst.txt"
          rel="nofollow">Page source</a></li>
    </div>

    

    
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-66327435-5']);
      _gaq.push(['_setDomainName', 'none']);
      _gaq.push(['_setAllowLinker', true]);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
    
  </body>
</html>